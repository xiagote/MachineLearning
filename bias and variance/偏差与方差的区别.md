https://blog.csdn.net/hertzcat/article/details/80035330 (吴恩达机器学习:方差与偏差)

#### 数据集划分

　　为了评价模型,我们通常将数据集分为三个部分,60%的训练集、20%的交叉验证集和20%的测试集,并使用误差作为模型使用在这些集合上的评价.评价的形式与之前的代价函数相同.(线性回归误差函数如下):

$$J_s(\theta) = \frac{1}{2m_s} \sum_{i=1}^{m_s}(h_{\theta}(x_s^{(i)}) - y_s(i))^2\ \ \ (s=train,cv,test)$$

　　在被划分的集合中,我们使用训练集来参数$\theta$,使用交叉验证集来选择模型(比如该使用多少次多项式特征),使用测试集来评估模型的预测能力.

#### 方差与偏差

　　当我们的模型表现不佳时,通常是出现两种问题,一种是 <font color= '#dd0000'>高偏差</font> 问题,另一种是  <font color= '#dd0000'>高方差</font> 问题.识别它们有助于选择正确的优化方法,所以我们先看下<font color= '#dd0000'>偏差</font> 与<font color= '#dd0000'>方差</font> 的意义

　　-偏差:描述模型输出结果的期望与样本真实结果的差距

　　-方差:描述模型对于给定值的输出稳定性.

<div align=center><img width="400" height="200" src="https://github.com/xiagote/MachineLearning/blob/master/bias%20and%20variance/bias_and_variance.png"/></div>

　　就像打靶一样,偏差描述了我们的射击总体是否偏离了我们的目标,而方差描述了射击准不准.接下来我们通过各种情况下<font color= '#dd0000'>训练集</font> 与<font color= '#dd0000'>交叉验证集</font>的误差曲线来直观地理解 <font color= '#dd0000'>偏差</font> 与<font color= '#dd0000'>方差</font> 的意义

　　对于多项式回归,当次数选取较低时,我们的训练集误差和交叉验证集误差都会很大;当次数选择刚刚好时,训练误差和交叉验证误差都很小;但当次数过大时会产生过拟合,虽然训练误差很小,但交叉验证误差会很大(关系图如下)

<div align=center><img width="400" height="200" src="https://github.com/xiagote/MachineLearning/blob/master/bias%20and%20variance/err_polynomial.png"/></div>

　　所以我们可以计算$J_{train}(\theta)$和$J_{cv}(\theta)$,如果他们同时很大的化,就是遇到了高偏差问题;

<div align=center><img width="400" height="200" src="https://github.com/xiagote/MachineLearning/blob/master/bias%20and%20variance/err_polynomial_2.png"/></div>

　　对于正则化参数,使用同样的分析方法,当参数比较小时容易产生过拟合现象,也就是高方差问题.而参数比较大时容易产生欠拟合现象,就是高偏差.

#### 学习曲线

　　无论你是要检查学习算法是否正常工作或需要改进算法的算法的表现,学习曲线都是一个十分直观有效的工具.学习曲线的横轴是样本数,纵轴为训练集和交叉验证集的误差.所以在一开始,由于样本数少,$J_{train}(\theta)$几乎没有,而$J_{cv}(\theta)$则非常大.随着样本数的增加,$J_{train}(\theta)$不断增大,而$J_{cv}(\theta)$因为训练数据增加而拟合得更好因此下降.所以学习曲线如下图:


<div align=center><img width="400" height="200" src="https://github.com/xiagote/MachineLearning/blob/master/bias%20and%20variance/learning_curve1.png"/></div>

　　在高偏差的情形下,$J_{train}(\theta)$与$J_{cv}(\theta)$已经十分接近,但是误差看大.这时候一味地增加样本数并不能给算法的性能带来提升.

<div align=center><img width="400" height="200" src="https://github.com/xiagote/MachineLearning/blob/master/bias%20and%20variance/learning_curve2.png"/></div>

　　在高方差的情形下,$J_{train}(\theta)$的误差较小,$J_{cv}(\theta)$比较大,这时搜集更多的样本很可能带来帮助.

<div align=center><img width="400" height="200" src="https://github.com/xiagote/MachineLearning/blob/master/bias%20and%20variance/learning_curve3.png"/></div>
